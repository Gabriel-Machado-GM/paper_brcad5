{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f453cca4-3a19-4d4e-88f2-c33655481aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0' #'-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a8db8b-3793-45ec-b1be-ca67d7fb833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from argparse import Namespace\n",
    "from datetime import timedelta\n",
    "from multiprocessing import cpu_count\n",
    "from typing import Any, List, Optional, Tuple, Union, Dict\n",
    "\n",
    "\n",
    "import IPython\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import transformers\n",
    "import wandb\n",
    "from fastai import *\n",
    "from fastai.basics import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.metrics import *\n",
    "from fastai.metrics import CMScores\n",
    "from fastai.text import *\n",
    "from fastai.utils.ipython import *\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                             classification_report, confusion_matrix, f1_score,\n",
    "                             matthews_corrcoef)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from torch import nn as nn\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import Metric\n",
    "from transformers import (AdamW, AutoConfig, AutoModel, AutoModelWithLMHead,\n",
    "                          AutoTokenizer, BertConfig, BertModel, BertTokenizer,\n",
    "                          BigBirdTokenizer, get_linear_schedule_with_warmup)\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a03edc-12b3-4377-bff5-3d2b438b217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@np_func\n",
    "def mcc(inp,targ): return matthews_corrcoef(targ, np.argmax(inp, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1561fef0-ebf0-45ed-a1b7-33b644e7aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet('../data/test_en.parquet')\n",
    "df_humans = pd.read_parquet('../data/humans_en.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb4f625-aab8-4763-8376-2f518215cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b12cf-25b0-44cc-908f-2f19f3df2c0c",
   "metadata": {},
   "source": [
    "# ULMFiT forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3450b3b-67bd-4b17-88a5-af291debf7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn_test_fwd = load_learner(os.getcwd(), 'saved_models_ulmfit/ulmfit_forward_exported', backwards=False)\n",
    "# learn_humans_fwd = load_learner(os.getcwd(), 'saved_models_ulmfit/ulmfit_forward_exported', backwards=False)\n",
    "ulmfit_fwd = load_learner(os.getcwd(), 'saved_models_ulmfit/ulmfit_forward_exported', backwards=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a813b2ae-8ff7-4958-b9da-79c48e437737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ULMFiT-fwd (690, 38) humans RNNLearner(data=TextClasDataBunch;\n",
      "\n",
      "Train: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Valid: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Test: None, model=SequentialRNN(\n",
      "  (0): MultiBatchEncoder(\n",
      "    (module): AWD_LSTM(\n",
      "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
      "      (encoder_dp): EmbeddingDropout(\n",
      "        (emb): Embedding(60000, 400, padding_idx=1)\n",
      "      )\n",
      "      (rnns): ModuleList(\n",
      "        (0): WeightDropout(\n",
      "          (module): LSTM(400, 1152, batch_first=True)\n",
      "        )\n",
      "        (1): WeightDropout(\n",
      "          (module): LSTM(1152, 1152, batch_first=True)\n",
      "        )\n",
      "        (2): WeightDropout(\n",
      "          (module): LSTM(1152, 400, batch_first=True)\n",
      "        )\n",
      "      )\n",
      "      (input_dp): RNNDropout()\n",
      "      (hidden_dps): ModuleList(\n",
      "        (0): RNNDropout()\n",
      "        (1): RNNDropout()\n",
      "        (2): RNNDropout()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): PoolingLinearClassifier(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.12, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=100, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9013352ee0>, <function error_rate at 0x7f901335e160>, <function mcc at 0x7f9010cd7160>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/media/nas-elias/tesla4/jefs5/paper/code'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
      "learn: ...\n",
      "alpha: 2.0\n",
      "beta: 1.0], layer_groups=[Sequential(\n",
      "  (0): Embedding(60000, 400, padding_idx=1)\n",
      "  (1): Embedding(60000, 400, padding_idx=1)\n",
      "  (2): LSTM(400, 1152, batch_first=True)\n",
      "  (3): LSTM(1152, 1152, batch_first=True)\n",
      "  (4): LSTM(1152, 400, batch_first=True)\n",
      "  (5): RNNDropout()\n",
      "  (6): RNNDropout()\n",
      "  (7): RNNDropout()\n",
      "  (8): RNNDropout()\n",
      "  (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Dropout(p=0.12, inplace=False)\n",
      "  (11): Linear(in_features=1200, out_features=100, bias=True)\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): Dropout(p=0.1, inplace=False)\n",
      "  (15): Linear(in_features=100, out_features=2, bias=True)\n",
      ")], add_time=True, silent=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='690' class='' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [690/690 04:40<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'ULMFiT-fwd'\n",
    "\n",
    "DS_TYPE = 'humans'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "MODEL = ulmfit_fwd\n",
    "\n",
    "print(MODEL_NAME, DS.shape, DS_TYPE, MODEL)\n",
    "\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "output_preds = list()\n",
    "for ruling in bar:\n",
    "    output_preds.append(MODEL.predict(ruling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf7f0c3-4281-4e7b-9b38-f5bf01764da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_pred          y_true       model ds_type\n",
       "0    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd  humans\n",
       "1    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd  humans\n",
       "2    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd  humans\n",
       "3    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd  humans\n",
       "4    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd  humans\n",
       "..              ...             ...         ...     ...\n",
       "685  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-fwd  humans\n",
       "686  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd  humans\n",
       "687  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd  humans\n",
       "688      PROVIMENTO      PROVIMENTO  ULMFiT-fwd  humans\n",
       "689  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-fwd  humans\n",
       "\n",
       "[690 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.Series([int(i[0]) for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].replace({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed8ea73-41f0-4627-89d1-a03cdc5da063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ULMFiT-fwd (76299, 36) test RNNLearner(data=TextClasDataBunch;\n",
      "\n",
      "Train: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Valid: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Test: None, model=SequentialRNN(\n",
      "  (0): MultiBatchEncoder(\n",
      "    (module): AWD_LSTM(\n",
      "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
      "      (encoder_dp): EmbeddingDropout(\n",
      "        (emb): Embedding(60000, 400, padding_idx=1)\n",
      "      )\n",
      "      (rnns): ModuleList(\n",
      "        (0): WeightDropout(\n",
      "          (module): LSTM(400, 1152, batch_first=True)\n",
      "        )\n",
      "        (1): WeightDropout(\n",
      "          (module): LSTM(1152, 1152, batch_first=True)\n",
      "        )\n",
      "        (2): WeightDropout(\n",
      "          (module): LSTM(1152, 400, batch_first=True)\n",
      "        )\n",
      "      )\n",
      "      (input_dp): RNNDropout()\n",
      "      (hidden_dps): ModuleList(\n",
      "        (0): RNNDropout()\n",
      "        (1): RNNDropout()\n",
      "        (2): RNNDropout()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): PoolingLinearClassifier(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.12, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=100, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9013352ee0>, <function error_rate at 0x7f901335e160>, <function mcc at 0x7f9010cd7160>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/media/nas-elias/tesla4/jefs5/paper/code'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
      "learn: ...\n",
      "alpha: 2.0\n",
      "beta: 1.0], layer_groups=[Sequential(\n",
      "  (0): Embedding(60000, 400, padding_idx=1)\n",
      "  (1): Embedding(60000, 400, padding_idx=1)\n",
      "  (2): LSTM(400, 1152, batch_first=True)\n",
      "  (3): LSTM(1152, 1152, batch_first=True)\n",
      "  (4): LSTM(1152, 400, batch_first=True)\n",
      "  (5): RNNDropout()\n",
      "  (6): RNNDropout()\n",
      "  (7): RNNDropout()\n",
      "  (8): RNNDropout()\n",
      "  (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Dropout(p=0.12, inplace=False)\n",
      "  (11): Linear(in_features=1200, out_features=100, bias=True)\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): Dropout(p=0.1, inplace=False)\n",
      "  (15): Linear(in_features=100, out_features=2, bias=True)\n",
      ")], add_time=True, silent=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='76299' class='' max='76299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [76299/76299 9:02:56<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'ULMFiT-fwd'\n",
    "\n",
    "DS_TYPE = 'test'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "MODEL = ulmfit_fwd\n",
    "\n",
    "print(MODEL_NAME, DS.shape, DS_TYPE, MODEL)\n",
    "\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "output_preds = list()\n",
    "for ruling in bar:\n",
    "    output_preds.append(MODEL.predict(ruling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20554ad3-1f3c-424f-b8c0-d6da3cc999a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76294</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76295</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76296</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76297</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76298</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-fwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               y_pred          y_true       model ds_type\n",
       "0      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd    test\n",
       "1      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd    test\n",
       "2      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd    test\n",
       "3      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd    test\n",
       "4      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd    test\n",
       "...               ...             ...         ...     ...\n",
       "76294  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-fwd    test\n",
       "76295  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-fwd    test\n",
       "76296  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-fwd    test\n",
       "76297  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-fwd    test\n",
       "76298      PROVIMENTO      PROVIMENTO  ULMFiT-fwd    test\n",
       "\n",
       "[76299 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_preds = pd.Series([int(i[0]) for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].map({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531c3b6-a69a-44e7-a989-eaa3c94463ae",
   "metadata": {},
   "source": [
    "# ULMFiT backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84c7258-26d4-42d4-8b31-5b46f1dcdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44de3aaa-001e-487a-87a3-d3f8962cfd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ulmfit_bwd = load_learner(os.getcwd(), 'saved_models_ulmfit/ulmfit_backward_exported', backwards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7400280f-2632-4da5-87c2-c20ca22c6d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ULMFiT-bwd (690, 38) humans RNNLearner(data=TextClasDataBunch;\n",
      "\n",
      "Train: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Valid: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Test: None, model=SequentialRNN(\n",
      "  (0): MultiBatchEncoder(\n",
      "    (module): AWD_LSTM(\n",
      "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
      "      (encoder_dp): EmbeddingDropout(\n",
      "        (emb): Embedding(60000, 400, padding_idx=1)\n",
      "      )\n",
      "      (rnns): ModuleList(\n",
      "        (0): WeightDropout(\n",
      "          (module): LSTM(400, 1152, batch_first=True)\n",
      "        )\n",
      "        (1): WeightDropout(\n",
      "          (module): LSTM(1152, 1152, batch_first=True)\n",
      "        )\n",
      "        (2): WeightDropout(\n",
      "          (module): LSTM(1152, 400, batch_first=True)\n",
      "        )\n",
      "      )\n",
      "      (input_dp): RNNDropout()\n",
      "      (hidden_dps): ModuleList(\n",
      "        (0): RNNDropout()\n",
      "        (1): RNNDropout()\n",
      "        (2): RNNDropout()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): PoolingLinearClassifier(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.12, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=100, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f7ce3538ee0>, <function error_rate at 0x7f7ce3543160>, <function mcc at 0x7f7ce0eb10d0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/media/nas-elias/tesla4/jefs5/paper/code'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
      "learn: ...\n",
      "alpha: 2.0\n",
      "beta: 1.0], layer_groups=[Sequential(\n",
      "  (0): Embedding(60000, 400, padding_idx=1)\n",
      "  (1): Embedding(60000, 400, padding_idx=1)\n",
      "  (2): LSTM(400, 1152, batch_first=True)\n",
      "  (3): LSTM(1152, 1152, batch_first=True)\n",
      "  (4): LSTM(1152, 400, batch_first=True)\n",
      "  (5): RNNDropout()\n",
      "  (6): RNNDropout()\n",
      "  (7): RNNDropout()\n",
      "  (8): RNNDropout()\n",
      "  (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Dropout(p=0.12, inplace=False)\n",
      "  (11): Linear(in_features=1200, out_features=100, bias=True)\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): Dropout(p=0.1, inplace=False)\n",
      "  (15): Linear(in_features=100, out_features=2, bias=True)\n",
      ")], add_time=True, silent=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='690' class='' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [690/690 04:26<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'ULMFiT-bwd'\n",
    "\n",
    "DS_TYPE = 'humans'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "MODEL = ulmfit_bwd\n",
    "\n",
    "print(MODEL_NAME, DS.shape, DS_TYPE, MODEL)\n",
    "\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "output_preds = list()\n",
    "for ruling in bar:\n",
    "    output_preds.append(MODEL.predict(ruling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea078483-193f-4b5b-9058-5d6959e291c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_pred          y_true       model ds_type\n",
       "0    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd  humans\n",
       "1    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd  humans\n",
       "2    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd  humans\n",
       "3    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd  humans\n",
       "4    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd  humans\n",
       "..              ...             ...         ...     ...\n",
       "685      PROVIMENTO      PROVIMENTO  ULMFiT-bwd  humans\n",
       "686  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd  humans\n",
       "687  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd  humans\n",
       "688      PROVIMENTO      PROVIMENTO  ULMFiT-bwd  humans\n",
       "689  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-bwd  humans\n",
       "\n",
       "[690 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.Series([int(i[0]) for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].replace({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654faf49-e49a-4b4d-99d2-c36ea4670f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ULMFiT-bwd (76299, 36) test RNNLearner(data=TextClasDataBunch;\n",
      "\n",
      "Train: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Valid: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: /media/nas-elias/tesla4/jefs5/paper/code;\n",
      "\n",
      "Test: None, model=SequentialRNN(\n",
      "  (0): MultiBatchEncoder(\n",
      "    (module): AWD_LSTM(\n",
      "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
      "      (encoder_dp): EmbeddingDropout(\n",
      "        (emb): Embedding(60000, 400, padding_idx=1)\n",
      "      )\n",
      "      (rnns): ModuleList(\n",
      "        (0): WeightDropout(\n",
      "          (module): LSTM(400, 1152, batch_first=True)\n",
      "        )\n",
      "        (1): WeightDropout(\n",
      "          (module): LSTM(1152, 1152, batch_first=True)\n",
      "        )\n",
      "        (2): WeightDropout(\n",
      "          (module): LSTM(1152, 400, batch_first=True)\n",
      "        )\n",
      "      )\n",
      "      (input_dp): RNNDropout()\n",
      "      (hidden_dps): ModuleList(\n",
      "        (0): RNNDropout()\n",
      "        (1): RNNDropout()\n",
      "        (2): RNNDropout()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): PoolingLinearClassifier(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.12, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=100, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=100, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f7ce3538ee0>, <function error_rate at 0x7f7ce3543160>, <function mcc at 0x7f7ce0eb10d0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/media/nas-elias/tesla4/jefs5/paper/code'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
      "learn: ...\n",
      "alpha: 2.0\n",
      "beta: 1.0], layer_groups=[Sequential(\n",
      "  (0): Embedding(60000, 400, padding_idx=1)\n",
      "  (1): Embedding(60000, 400, padding_idx=1)\n",
      "  (2): LSTM(400, 1152, batch_first=True)\n",
      "  (3): LSTM(1152, 1152, batch_first=True)\n",
      "  (4): LSTM(1152, 400, batch_first=True)\n",
      "  (5): RNNDropout()\n",
      "  (6): RNNDropout()\n",
      "  (7): RNNDropout()\n",
      "  (8): RNNDropout()\n",
      "  (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Dropout(p=0.12, inplace=False)\n",
      "  (11): Linear(in_features=1200, out_features=100, bias=True)\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): Dropout(p=0.1, inplace=False)\n",
      "  (15): Linear(in_features=100, out_features=2, bias=True)\n",
      ")], add_time=True, silent=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='76299' class='' max='76299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [76299/76299 8:26:46<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'ULMFiT-bwd'\n",
    "\n",
    "DS_TYPE = 'test'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "MODEL = ulmfit_bwd\n",
    "\n",
    "print(MODEL_NAME, DS.shape, DS_TYPE, MODEL)\n",
    "\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "output_preds = list()\n",
    "for ruling in bar:\n",
    "    output_preds.append(MODEL.predict(ruling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b3d701-0c3e-49a9-905a-f6b6a102bbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76294</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76295</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76296</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76297</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76298</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bwd</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               y_pred          y_true       model ds_type\n",
       "0      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd    test\n",
       "1      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd    test\n",
       "2      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd    test\n",
       "3      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd    test\n",
       "4      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd    test\n",
       "...               ...             ...         ...     ...\n",
       "76294      PROVIMENTO      PROVIMENTO  ULMFiT-bwd    test\n",
       "76295      PROVIMENTO      PROVIMENTO  ULMFiT-bwd    test\n",
       "76296  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bwd    test\n",
       "76297      PROVIMENTO      PROVIMENTO  ULMFiT-bwd    test\n",
       "76298      PROVIMENTO      PROVIMENTO  ULMFiT-bwd    test\n",
       "\n",
       "[76299 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_preds = pd.Series([int(i[0]) for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].map({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29eb82-7461-40a8-8fbb-4fd1a780b20a",
   "metadata": {},
   "source": [
    "# ULMFiT bidir ( (forward + backward) / 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd395ad-c2df-4cf0-9063-787e07d857a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ULMFiT-bidir'\n",
    "\n",
    "DS_TYPE = 'humans'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "\n",
    "preds_fwd = joblib.load(f'predictions/raw-ULMFiT-fwd-{DS_TYPE}.joblib')\n",
    "preds_bwd = joblib.load(f'predictions/raw-ULMFiT-bwd-{DS_TYPE}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cb4d181-7c14-4516-ac83-535a6d65f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_fwd = torch.stack([i[2] for i in preds_fwd])\n",
    "probs_bwd = torch.stack([i[2] for i in preds_bwd])\n",
    "probs_bidir = (probs_bwd + probs_fwd) / 2\n",
    "preds = np.argmax(probs_bidir, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c34501a-62a5-4936-85c6-dd43f85e3c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_pred          y_true         model ds_type\n",
       "0    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir  humans\n",
       "1    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir  humans\n",
       "2    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir  humans\n",
       "3    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir  humans\n",
       "4    NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir  humans\n",
       "..              ...             ...           ...     ...\n",
       "685  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-bidir  humans\n",
       "686  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir  humans\n",
       "687  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir  humans\n",
       "688      PROVIMENTO      PROVIMENTO  ULMFiT-bidir  humans\n",
       "689  NÃO PROVIMENTO      PROVIMENTO  ULMFiT-bidir  humans\n",
       "\n",
       "[690 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_preds = pd.Series([int(i) for i in preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].map({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e789e3-c089-46f1-82f6-f457ae099216",
   "metadata": {},
   "source": [
    "# ULMFiT bidir ( (forward + backward) / 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "455cef77-7ba1-4226-8c61-2fa468176376",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ULMFiT-bidir'\n",
    "\n",
    "DS_TYPE = 'test'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "\n",
    "preds_fwd = joblib.load(f'predictions/raw-ULMFiT-fwd-{DS_TYPE}.joblib')\n",
    "preds_bwd = joblib.load(f'predictions/raw-ULMFiT-bwd-{DS_TYPE}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eefbee1-18c1-4283-aea1-192d664786ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_fwd = torch.stack([i[2] for i in preds_fwd])\n",
    "probs_bwd = torch.stack([i[2] for i in preds_bwd])\n",
    "probs_bidir = (probs_bwd + probs_fwd) / 2\n",
    "preds = np.argmax(probs_bidir, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a868c849-6bab-4f8d-b60e-1f4aa3971a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76294</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76295</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76296</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76297</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76298</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>ULMFiT-bidir</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               y_pred          y_true         model ds_type\n",
       "0      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir    test\n",
       "1      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir    test\n",
       "2      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir    test\n",
       "3      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir    test\n",
       "4      NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir    test\n",
       "...               ...             ...           ...     ...\n",
       "76294      PROVIMENTO      PROVIMENTO  ULMFiT-bidir    test\n",
       "76295      PROVIMENTO      PROVIMENTO  ULMFiT-bidir    test\n",
       "76296  NÃO PROVIMENTO  NÃO PROVIMENTO  ULMFiT-bidir    test\n",
       "76297      PROVIMENTO      PROVIMENTO  ULMFiT-bidir    test\n",
       "76298      PROVIMENTO      PROVIMENTO  ULMFiT-bidir    test\n",
       "\n",
       "[76299 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_preds = pd.Series([int(i) for i in preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].map({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889a0e3-cad6-457a-85b4-854fcc6bd2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5ac82d6-1401-4d1d-b8c6-9d321c3bdaee",
   "metadata": {},
   "source": [
    "# BERT + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cb789f-c64d-47c8-9225-878eb1f245db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "class MCC(Metric):\n",
    " \n",
    "    def __init__(\n",
    "        self,\n",
    "        compute_on_step: bool = True,\n",
    "        dist_sync_on_step: bool = False,\n",
    "        process_group: Optional[Any] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            compute_on_step=compute_on_step,\n",
    "            dist_sync_on_step=dist_sync_on_step,\n",
    "            process_group=process_group,\n",
    "        )\n",
    "        self.add_state(\"preds\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"target\", default=[], dist_reduce_fx=None)\n",
    "\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        self.preds.append(preds.flatten().long())\n",
    "        self.target.append(target.flatten().long())\n",
    "\n",
    "    def compute(self) -> Union[Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
    "                               Tuple[List[torch.Tensor], List[torch.Tensor], List[torch.Tensor]]]:\n",
    "\n",
    "        preds = torch.cat(self.preds, dim=0).cpu().numpy()\n",
    "        target = torch.cat(self.target, dim=0).cpu().numpy()\n",
    "        return matthews_corrcoef(preds, target), preds, target\n",
    "\n",
    "\n",
    "class ModelBERTLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name: str, bertconfig: BertConfig, n_layers_lstm:int, bidir_lstm:bool, drop_mult: float, use_special_classifier:str, output_lstm_size:int, distil_init: bool):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = transformers.BertModel.from_pretrained(model_name)#.bert\n",
    "        self.bert.config = bertconfig\n",
    "        self.dropout_mult = drop_mult\n",
    "        self.dropout = nn.Dropout(p=self.dropout_mult)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size * 4,\n",
    "                            output_lstm_size,\n",
    "                            num_layers=n_layers_lstm,\n",
    "                            dropout=self.dropout_mult if n_layers_lstm > 1 else 0,\n",
    "                            bidirectional=bidir_lstm)\n",
    "\n",
    "        sizes_classifier = [output_lstm_size * (2 if bidir_lstm else 1), int(self.bert.config.hidden_size//2), 1]\n",
    "\n",
    "        if use_special_classifier == 'ln': \n",
    "            self.classifier = nn.Sequential(\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[0], sizes_classifier[1]),\n",
    "                nn.LayerNorm(sizes_classifier[1]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[1], sizes_classifier[2]),\n",
    "                nn.LayerNorm(sizes_classifier[2])\n",
    "            )\n",
    "        elif use_special_classifier == 'bn': \n",
    "            self.classifier = nn.Sequential(\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[0], sizes_classifier[1]),\n",
    "                nn.BatchNorm1d(sizes_classifier[1]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[1], sizes_classifier[2]),\n",
    "                nn.BatchNorm1d(sizes_classifier[2])\n",
    "            )\n",
    "        elif use_special_classifier == 'none': \n",
    "            self.classifier = nn.Sequential(\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[0], sizes_classifier[1]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[1], sizes_classifier[2])\n",
    "            )\n",
    "\n",
    "        # DistilBERT’s custom initialization\n",
    "        # https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/\n",
    "\n",
    "        if distil_init:\n",
    "            for layer in self.classifier:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                    if layer.bias is not None:\n",
    "                        layer.bias.data.zero_()\n",
    "\n",
    "    #input_ids, token_type_ids, attention_masks\n",
    "    def forward(self, document_batch: torch.Tensor, document_sequence_lengths: list, device='cuda'):\n",
    "\n",
    "        # contains all BERT sequences\n",
    "        # bert should output a (batch_size, num_sequences, bert_hidden_size)\n",
    "        bert_output = torch.zeros(size=(document_batch.shape[0],\n",
    "                                           min(document_batch.shape[1], self.bert.config.batch_size),\n",
    "                                           self.bert.config.hidden_size*4), dtype=torch.float, device=device)\n",
    "       # pdb.set_trace() # DEBUG\n",
    "        # only pass through bert_batch_size numbers of inputs into bert. #\n",
    "        # this means that we are possibly cutting off the last part of documents.\n",
    "\n",
    "        for doc_id in range(document_batch.shape[0]):\n",
    "            out_bert = self.bert(document_batch[doc_id][:self.bert.config.batch_size, 0],\n",
    "                                       token_type_ids=document_batch[doc_id][:self.bert.config.batch_size, 1],\n",
    "                                       attention_mask=document_batch[doc_id][:self.bert.config.batch_size, 2], output_hidden_states=True)#[0][:, 0, :]\n",
    "\n",
    "\n",
    "            hidden_states = out_bert[2]\n",
    "            h12 = hidden_states[-1][:,0]\n",
    "            h11 = hidden_states[-2][:,0]\n",
    "            h10 = hidden_states[-3][:,0]\n",
    "            h09 = hidden_states[-4][:,0]\n",
    "            concat_hidden = torch.cat([h09, h10, h11, h12], axis=-1)\n",
    "            \n",
    "            bert_output[doc_id][:self.bert.config.batch_size] = concat_hidden\n",
    "\n",
    "        lista = []\n",
    "        for idx, i in enumerate(document_sequence_lengths+1):\n",
    "            lista.append(bert_output[idx, :int(i)])\n",
    "        packed = pack_sequence(lista, enforce_sorted=False)        \n",
    "        self.lstm.flatten_parameters()\n",
    "        output, (_, _) = self.lstm(packed)\n",
    "        output, _ = pad_packed_sequence(output) # TODO ESTUDAR MELHOR ESSA SAIDA\n",
    "        indexes =  [len(i) -1 for i in lista]  # x is the input, which is a list contains sentence embeddings in a batch\n",
    "\n",
    "        last_layer = output[indexes, range(output.shape[1]), :]\n",
    "        out = self.classifier(last_layer)\n",
    "        return out\n",
    "\n",
    "    def freeze_bert_encoder(self):\n",
    "        print('Freezing all bert encoder')\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert_encoder(self):\n",
    "        print('Unreezing all bert encoder')\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze_bert_encoder_last_layers(self):\n",
    "        print('Unfreezing bert encoder last layers')\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            if \"encoder.layer.11\" in name or \"pooler\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def unfreeze_bert_encoder_pooler_layer(self):\n",
    "        print('Unfreezing bert encoder last pooler layer')\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            if \"pooler\" in name:\n",
    "                print(name)\n",
    "                param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "class EncodeCollateFn:\n",
    "\n",
    "\n",
    "    def __init__(self, tokenizer: AutoTokenizer, bert_batch_size, max_input_length=512):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_tokens = max_input_length\n",
    "        self.bert_batch_size = bert_batch_size\n",
    "\n",
    "    def get_sliding_window_tokens(self, text: str):\n",
    "        cut = self.bert_batch_size\n",
    "        raw_tokens = self.tokenizer.tokenize(text)\n",
    "        tokens = {}\n",
    "        input_type_ids = {}\n",
    "        attention_masks = {}\n",
    "\n",
    "        if len(raw_tokens) > (self.max_tokens-2)*cut:\n",
    "            max_inicio = math.floor(cut/2)\n",
    "            max_fim = math.ceil(cut/2)\n",
    "            all_tokens = raw_tokens[:(self.max_tokens-2)*max_inicio] + raw_tokens[-(self.max_tokens-2)*max_fim:]\n",
    "            was_cut = True\n",
    "        else:\n",
    "            all_tokens = raw_tokens\n",
    "            was_cut = False\n",
    "\n",
    "        def chunks(lista, n):\n",
    "            n = max(1, n)\n",
    "            return [lista[i:i+n] for i in range(0, len(lista), n)]\n",
    "\n",
    "        def fill(lista, desired_length, filler=0):\n",
    "            if len(lista) >= desired_length:\n",
    "                return lista\n",
    "\n",
    "            current_size = len(lista)\n",
    "            n = desired_length - current_size\n",
    "            listofzeros = [filler] * n\n",
    "            lista += listofzeros\n",
    "            return lista\n",
    "            \n",
    "        tokens_split = chunks(all_tokens, self.max_tokens-2)\n",
    "        tokens_split = [[\"CLS\"] + chunk + [\"[SEP\"] for chunk in tokens_split]\n",
    "\n",
    "        for n, split in enumerate(tokens_split):\n",
    "            tokens[n] = np.array(fill(self.tokenizer.convert_tokens_to_ids(split), self.max_tokens, self.tokenizer.pad_token_id))\n",
    "            input_type_ids[n] = np.array(fill([0] * len(split), self.max_tokens, 0))\n",
    "            attention_masks[n] = np.array(fill([1] * len(split), self.max_tokens, 0))\n",
    "\n",
    "        retorno = {\n",
    "            'original_len': len(raw_tokens),\n",
    "            'n_chunks': len(tokens.keys()),\n",
    "            'tokenized_chunks': {\n",
    "                'input_ids': tokens,\n",
    "                'input_type_ids': input_type_ids,\n",
    "                'attention_masks': attention_masks\n",
    "            },\n",
    "            'was_cut': was_cut\n",
    "        }\n",
    "        return retorno    \n",
    "\n",
    "\n",
    "    def __call__(self, batch):\n",
    "\n",
    "        documents = [x[0] for x in batch]\n",
    "\n",
    "        assert type(documents) == list, 'Needs to be a list of strings'\n",
    "\n",
    "        split_documents = list()\n",
    "\n",
    "        for document in documents:\n",
    "            split_documents.append(self.get_sliding_window_tokens(text=document))\n",
    "\n",
    "        max_sequences_per_document = math.ceil(max([i['n_chunks'] for i in split_documents]))\n",
    "\n",
    "        assert max_sequences_per_document <= 15, f\"Your document is way too large\"\n",
    "\n",
    "        output = torch.zeros(size=(len(documents), max_sequences_per_document, 3, 512), dtype=torch.long)\n",
    "        document_seq_lengths = []  # number of sequence generated per document\n",
    "\n",
    "        for doc_index, split_document in enumerate(split_documents):\n",
    "            for seq_index in range(split_document['n_chunks']):\n",
    "                    \n",
    "                input_ids = split_document['tokenized_chunks']['input_ids'][seq_index]#.squeeze()\n",
    "                attention_masks = split_document['tokenized_chunks']['attention_masks'][seq_index]#.squeeze()\n",
    "                input_type_ids = split_document['tokenized_chunks']['attention_masks'][seq_index]#.squeeze()\n",
    "    \n",
    "\n",
    "                assert len(input_ids) == self.max_tokens and len(attention_masks) == self.max_tokens and len(input_type_ids) == self.max_tokens, f\"{len(input_ids)} - {len(attention_masks)} - {len(input_type_ids)}\"\n",
    "\n",
    "                # we are ready to rumble\n",
    "                output[doc_index][seq_index] = torch.cat((torch.LongTensor(input_ids).unsqueeze(0),\n",
    "                                                          torch.LongTensor(input_type_ids).unsqueeze(0),\n",
    "                                                          torch.LongTensor(attention_masks).unsqueeze(0)),\n",
    "                                                         dim=0)\n",
    "                max_seq_index = seq_index\n",
    "            #document_seq_lengths.append(max_seq_index+1)\n",
    "            document_seq_lengths.append(split_document['n_chunks'])\n",
    "\n",
    "        labels = torch.tensor([x[1] for x in batch], dtype=torch.int8)\n",
    "        return (output, torch.LongTensor(document_seq_lengths)), labels\n",
    "    \n",
    "\n",
    "# from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)\n",
    "\n",
    "\n",
    "class JEFDataset(Dataset):\n",
    "    def __init__(self, path, dep_var, text_col, lowercase):\n",
    "        super().__init__()\n",
    "        self.dep_var = dep_var\n",
    "        self.text_col = text_col\n",
    "        all_columns = [self.dep_var, self.text_col] + ['date_appeal_panel_ruling']\n",
    "\n",
    "        data = pd.read_parquet(path, columns=all_columns)    \n",
    "\n",
    "        if len(data) > 600_000:\n",
    "            print(f'Previous size of training data: {len(data)}. Selecting only last 5 years of the training dataset')\n",
    "            data.date_appeal_panel_ruling = pd.to_datetime(data.date_appeal_panel_ruling, infer_datetime_format=True, yearfirst=True, dayfirst=False)\n",
    "            thresh = data.date_appeal_panel_ruling.max() - timedelta(days=365*5)\n",
    "            data = data[data.date_appeal_panel_ruling >= thresh].copy()\n",
    "            print(f'New size of training data: {len(data)}')\n",
    "\n",
    "        data.drop('date_appeal_panel_ruling', axis=1, inplace=True)\n",
    "        data[self.dep_var] = data[self.dep_var].replace('PROVIMENTO PARCIAL', 'PROVIMENTO')\n",
    "        data = data[data[self.dep_var].isin(['PROVIMENTO', 'NÃO PROVIMENTO'])]\n",
    "        data[self.dep_var] = data[self.dep_var].map({'NÃO PROVIMENTO': 0, 'PROVIMENTO': 1})\n",
    "\n",
    "        if lowercase:\n",
    "            data[self.text_col] = data[self.text_col].str.lower()\n",
    "\n",
    "        print(f'Size before: {len(data)} - {path.split(\"/\")[-1]}')        \n",
    "        data.dropna(inplace=True)\n",
    "        print(f'Size after: {len(data)} - {path.split(\"/\")[-1]}')\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        self.data = data.copy()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, self.text_col], self.data.loc[idx, self.dep_var]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.num_labels = len(self.hparams['labels'])\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.hparams['bert_model_path'])\n",
    "        config = AutoConfig.from_pretrained(self.hparams['bert_model_path'])\n",
    "        config.__setattr__('num_labels', len(self.hparams['labels']))\n",
    "        config.__setattr__('batch_size', self.hparams['bert_batch_size'])\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        self.mcc = MCC()\n",
    "        self.valor_mcc = {'val_mcc': -1, 'test_mcc': -1}\n",
    "        self.best_mcc = -1.0\n",
    "        self.precision_metric = torchmetrics.Precision(num_classes=self.num_labels)\n",
    "        self.recall_metric = torchmetrics.Recall(num_classes=self.num_labels)\n",
    "        #self.confmat = torchmetrics.ConfusionMatrix(num_classes=self.num_labels)\n",
    "        self.f1_score = torchmetrics.F1(num_classes=self.num_labels)\n",
    "\n",
    "        self.model = ModelBERTLSTM(self.hparams['bert_model_path'],\n",
    "                                      bertconfig=config,\n",
    "                                      n_layers_lstm=self.hparams.n_layers_lstm,\n",
    "                                      bidir_lstm=self.hparams.bidir_lstm,\n",
    "                                      drop_mult=self.hparams.drop_mult,\n",
    "                                      use_special_classifier=self.hparams.use_special_classifier,\n",
    "                                      output_lstm_size=self.hparams.output_lstm_size,\n",
    "                                      distil_init=self.hparams.distil_init)\n",
    "\n",
    "\n",
    "        if self.hparams.bert_unfreeze_mode == 'encoder_last':\n",
    "            self.model.freeze_bert_encoder()\n",
    "            self.model.unfreeze_bert_encoder_last_layers()\n",
    "        elif self.hparams.bert_unfreeze_mode == 'pooler_last':\n",
    "            self.model.freeze_bert_encoder()\n",
    "            self.model.unfreeze_bert_encoder_pooler_layer()\n",
    "        elif self.hparams.bert_unfreeze_mode == 'all':\n",
    "            self.model.unfreeze_bert_encoder()\n",
    "        elif self.hparams.bert_unfreeze_mode == 'none':\n",
    "            self.model.freeze_bert_encoder()\n",
    "\n",
    "        if self.hparams.weighted_loss:\n",
    "            weights = torch.FloatTensor(self.hparams.train_weights)\n",
    "            print(f'Using weighted loss: {weights}')\n",
    "        else:\n",
    "            weights = None\n",
    "        # weight = torch.FloatTensor(self.hparams.train_weights).to(self.hparams.device) if self.hparams.train_weights is not None else None)\n",
    "        self.loss = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "        self.lr = self.hparams.lr\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def step(self, batch, step_name='train'):\n",
    "        thresh = self.hparams.thresh_step\n",
    "        input_ids, attention_masks, y = batch\n",
    "        logits = self.forward(input_ids, attention_masks).squeeze()\n",
    "        y = y.type_as(logits)\n",
    "        loss = self.loss(logits, y)\n",
    "\n",
    "        if step_name == 'train':\n",
    "            self.log('train_loss', loss, on_step=True, on_epoch=True,\n",
    "                     logger=True, prog_bar=True, sync_dist=True, sync_dist_op='mean')\n",
    "            result = {'train_loss': loss}\n",
    "            return loss\n",
    "\n",
    "        else:\n",
    "            self.log(f'{step_name}_loss', loss, on_step=False, on_epoch=True, logger=True,\n",
    "                     prog_bar=True, reduce_fx=torch.mean, sync_dist=True, sync_dist_op='mean')\n",
    "\n",
    "            y_pred = torch.sigmoid(logits)\n",
    "            y_pred = torch.where(y_pred > thresh, 1.0, 0.0).long()\n",
    "            y =  y.long()\n",
    "            #y_pred = torch.argmax(logits, dim=1)\n",
    "            self.accuracy(y_pred, y)\n",
    "            #self.mymetric(y_pred, y)\n",
    "            self.precision_metric(y_pred, y)\n",
    "            self.recall_metric(y_pred, y)\n",
    "            self.f1_score(y_pred, y)\n",
    "            #self.confmat(y_pred, y)\n",
    "            self.mcc(y_pred, y)\n",
    "\n",
    "    \n",
    "        result = {f'{step_name}_loss': loss}\n",
    "        return result\n",
    "        \n",
    "    def calculate_metrics(self, outputs, step_name='val'):\n",
    "        \n",
    "        mcc, preds, target = self.mcc.compute()\n",
    "        tn = ((target == preds) & (target == 0)).sum()\n",
    "        tp = ((target == preds) & (target == 1)).sum()\n",
    "        fn = ((target != preds) & (target == 1)).sum()\n",
    "        fp = ((target != preds) & (target == 0)).sum()\n",
    "\n",
    "        \n",
    "        outs = {}\n",
    "        outs[f'{step_name}_acc'] = self.accuracy.compute()\n",
    "        outs[f'{step_name}_loss'] = torch.mean(torch.tensor([i[f'{step_name}_loss'] for i in outputs]))\n",
    "        outs[f'{step_name}_tn'] = tn\n",
    "        outs[f'{step_name}_fp'] = fp\n",
    "        outs[f'{step_name}_fn'] = fn\n",
    "        outs[f'{step_name}_tp'] = tp\n",
    "        outs[f'{step_name}_f1_score'] = self.f1_score.compute()\n",
    "        outs[f'{step_name}_precision'] = self.precision_metric.compute()\n",
    "        outs[f'{step_name}_recall'] = self.recall_metric.compute()\n",
    "        outs[f'{step_name}_mcc'] = mcc\n",
    "        #outs[f'{step_name}_mccold'] = mcc2\n",
    "        #confmat = self.confmat.compute().long().detach().cpu().numpy()\n",
    "\n",
    "        self.recall_metric.reset()\n",
    "        self.precision_metric.reset()\n",
    "        self.f1_score.reset()\n",
    "        self.accuracy.reset()\n",
    "        self.mcc.reset()\n",
    "        #self.confmat.reset()\n",
    "\n",
    "        if float(mcc) > self.best_mcc:\n",
    "            self.best_mcc = float(mcc)\n",
    "            self.log('best_mcc', mcc)\n",
    "        if self.valor_mcc[f'{step_name}_mcc'] < float(outs[f'{step_name}_mcc']):\n",
    "            self.valor_mcc[f'{step_name}_mcc'] = float(outs[f'{step_name}_mcc'])\n",
    "\n",
    "        print(matthews_corrcoef(preds, target), mcc, len(target), len(preds))\n",
    "        if self.global_rank == 0:\n",
    "            print(matthews_corrcoef(preds, target), mcc, len(target), len(preds))\n",
    "            if self.valor_mcc[f'{step_name}_mcc'] < float(outs[f'{step_name}_mcc']):\n",
    "                self.valor_mcc[f'{step_name}_mcc'] = float(outs[f'{step_name}_mcc'])\n",
    "                #self.logger.experiment.log({f\"best_mcc-confusion_matrix\" : wandb.plot.confusion_matrix(preds=preds, y_true=target, class_names=[i[:3].upper() for i in self.hparams.labels])}, commit=False)\n",
    "            #print(\"\\n\\nCONFUSION MATRIX:\\n\", confmat, \"\\n\")\n",
    "            print(f\"{step_name}_acc: {float(outs[f'{step_name}_acc']):.5f}\")\n",
    "            print(f\"{step_name}_mcc: {float(outs[f'{step_name}_mcc']):.5f}\")\n",
    "            print(f\"Number of cases: {int(tn+fp+fn+tp)}\")\n",
    "            print('\\n')\n",
    "\n",
    "\n",
    "        for k, v in outs.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "    def forward(self, X_text, *args):\n",
    "        return self.model(X_text[0], X_text[1], *args)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def validation_epoch_end(self, outputs: List[dict]):\n",
    "        return self.calculate_metrics(outputs, step_name='val')\n",
    "\n",
    "    def test_epoch_end(self, outputs: List[dict]):\n",
    "        return self.calculate_metrics(outputs, step_name='test')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "\n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        #print(self.hparams.cat_names)\n",
    "        return DataLoader(\n",
    "            JEFDataset(ds_path, self.hparams.dep_var, self.hparams.text_col, self.hparams.lowercase), \n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "            num_workers=int(cpu_count()),\n",
    "            collate_fn=EncodeCollateFn(self.tokenizer, self.hparams.bert_batch_size)\n",
    "        )\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == 'fit':\n",
    "            total_devices = max(1, self.hparams.n_gpus) * 1\n",
    "            train_batches = len(self.train_dataloader()) // total_devices\n",
    "            self.train_steps = math.ceil((self.hparams.epochs * train_batches) / self.hparams.accumulate_grad_batches)\n",
    "            self.train_steps = int(math.ceil(self.train_steps * 1.01))#1.04)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_steps = self.train_steps\n",
    "        optimizer = torch.optim.AdamW([p for p in self.model.parameters() if p.requires_grad], lr=self.lr, weight_decay=0.1)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                           max_lr=self.lr,\n",
    "                                                           total_steps=train_steps,\n",
    "                                                           three_phase=True,\n",
    "                                                           epochs=self.hparams.epochs)\n",
    "\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91877a7-daf1-4d95-b8d4-7463f832bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/envs/paper_brcad5/lib/python3.9/site-packages/deprecate/deprecation.py:115: FutureWarning: The `F1` was deprecated since v0.7 in favor of `torchmetrics.classification.f_beta.F1Score`. It will be removed in v0.8.\n",
      "  stream(template_mgs % msg_args)\n",
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing all bert encoder\n",
      "Unfreezing bert encoder last layers\n",
      "Using weighted loss: 3.8351831436157227\n"
     ]
    }
   ],
   "source": [
    "learn = TrainingModule.load_from_checkpoint('.//bert_lstm-best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703e9b2f-c991-4639-b04e-533b50563e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()\n",
    "learn.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b51489-07ad-4e4b-a4cf-4832ecba41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to('cuda:0'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ff97aa9-457a-4f69-9dfc-94c8d69c03dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a61a840-5069-40b4-9ae4-18ed31c934fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accumulate_grad_batches\": 3\n",
       "\"batch_size\":              8\n",
       "\"bert_batch_size\":         15\n",
       "\"bert_model_path\":         neuralmind/bert-base-portuguese-cased\n",
       "\"bert_unfreeze_mode\":      encoder_last\n",
       "\"bidir_lstm\":              False\n",
       "\"dep_var\":                 label\n",
       "\"deterministic\":           True\n",
       "\"device\":                  cuda\n",
       "\"distil_init\":             False\n",
       "\"drop_mult\":               0.1\n",
       "\"epochs\":                  8\n",
       "\"gradient_clip_val\":       0.0\n",
       "\"hparams\":                 Namespace(train_path='../data/train_en.parquet', val_path='../data/valid_en.parquet', test_path='../data/test_en.parquet', batch_size=8, epochs=8, drop_mult=0.1, n_layers_lstm=1, bidir_lstm=False, use_special_classifier='none', output_lstm_size=1536, lowercase=False, lr=0.0003, lr_divider=15, thresh_step=0.49, accumulate_grad_batches=3, gradient_clip_val=0.0, bert_batch_size=15, distil_init=False, stochastic_weight_avg=True, use_metadata=True, dep_var='label', text_col='preprocessed_full_text_first_instance_court_ruling', bert_model_path='neuralmind/bert-base-portuguese-cased', labels=[0, 1], sync_batchnorm=True, device='cuda', train_weights=array(3.835183, dtype=float32), bert_unfreeze_mode='encoder_last', weighted_loss=True, precision=16, n_gpus=2, deterministic=True)\n",
       "\"labels\":                  [0, 1]\n",
       "\"lowercase\":               False\n",
       "\"lr\":                      0.0003\n",
       "\"lr_divider\":              15\n",
       "\"n_gpus\":                  2\n",
       "\"n_layers_lstm\":           1\n",
       "\"output_lstm_size\":        1536\n",
       "\"precision\":               16\n",
       "\"stochastic_weight_avg\":   True\n",
       "\"sync_batchnorm\":          True\n",
       "\"test_path\":               ../data/test_en.parquet\n",
       "\"text_col\":                preprocessed_full_text_first_instance_court_ruling\n",
       "\"thresh_step\":             0.49\n",
       "\"train_path\":              ../data/train_en.parquet\n",
       "\"train_weights\":           3.8351831436157227\n",
       "\"use_metadata\":            True\n",
       "\"use_special_classifier\":  none\n",
       "\"val_path\":                ../data/valid_en.parquet\n",
       "\"weighted_loss\":           True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04518138-0add-45b0-a295-8c355e059a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    output, _ = EncodeCollateFn(model.tokenizer, model.hparams.bert_batch_size)([[text, 0]])\n",
    "    if model.device != 'cpu':\n",
    "        output = (output[0].to(model.device), output[1].to(model.device))\n",
    "    logits = model.forward(output)\n",
    "    prob  = torch.sigmoid(logits)\n",
    "    y_pred = torch.where(prob > model.hparams.thresh_step, 1.0, 0.0).long()\n",
    "    return logits.cpu().numpy(), prob.cpu().numpy(), int(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68af12af-741f-4eb6-92bc-eeeb05fb9329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='690' class='' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [690/690 00:29<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'BERT_LSTM'\n",
    "DS_TYPE = 'humans'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "\n",
    "output_preds = []\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "\n",
    "for ruling in bar:\n",
    "    output_preds.append(predict(learn, ruling))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acd40b99-07ba-4d85-bdb1-33c235623e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_preds[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "069e497e-5dc4-4d43-9013-581ac4fc5ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_pred          y_true      model ds_type\n",
       "0    NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM  humans\n",
       "1    NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM  humans\n",
       "2    NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM  humans\n",
       "3    NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM  humans\n",
       "4    NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM  humans\n",
       "..              ...             ...        ...     ...\n",
       "685  NÃO PROVIMENTO      PROVIMENTO  BERT_LSTM  humans\n",
       "686  NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM  humans\n",
       "687  NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM  humans\n",
       "688      PROVIMENTO      PROVIMENTO  BERT_LSTM  humans\n",
       "689      PROVIMENTO      PROVIMENTO  BERT_LSTM  humans\n",
       "\n",
       "[690 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.Series([i[2] for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].replace({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5579adc-b20a-4358-a2dc-ab8eb2d8b7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ce4d659-29ce-4926-80ca-88a00f03dafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='76299' class='' max='76299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [76299/76299 59:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'BERT_LSTM'\n",
    "DS_TYPE = 'test'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "\n",
    "output_preds = []\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "\n",
    "for ruling in bar:\n",
    "    output_preds.append(predict(learn, ruling))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4429d53-53fa-49cd-915c-72dd02e4fe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76294</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76295</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76296</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76297</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76298</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BERT_LSTM</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               y_pred          y_true      model ds_type\n",
       "0      NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM    test\n",
       "1          PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM    test\n",
       "2      NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM    test\n",
       "3      NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM    test\n",
       "4      NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM    test\n",
       "...               ...             ...        ...     ...\n",
       "76294      PROVIMENTO      PROVIMENTO  BERT_LSTM    test\n",
       "76295  NÃO PROVIMENTO      PROVIMENTO  BERT_LSTM    test\n",
       "76296  NÃO PROVIMENTO  NÃO PROVIMENTO  BERT_LSTM    test\n",
       "76297      PROVIMENTO      PROVIMENTO  BERT_LSTM    test\n",
       "76298      PROVIMENTO      PROVIMENTO  BERT_LSTM    test\n",
       "\n",
       "[76299 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.Series([i[2] for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].replace({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e5aaa-2337-411f-a240-5169f240c797",
   "metadata": {},
   "source": [
    "# BigBird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f60fcd-16a4-45b8-85ac-c2a5bdbd9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 314\n"
     ]
    }
   ],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "seed_everything(314)\n",
    "\n",
    "class MCC(Metric):\n",
    " \n",
    "    def __init__(\n",
    "        self,\n",
    "        compute_on_step: bool = True,\n",
    "        dist_sync_on_step: bool = False,\n",
    "        process_group: Optional[Any] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            compute_on_step=compute_on_step,\n",
    "            dist_sync_on_step=dist_sync_on_step,\n",
    "            process_group=process_group,\n",
    "        )\n",
    "        self.add_state(\"preds\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"target\", default=[], dist_reduce_fx=None)\n",
    "\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        self.preds.append(preds.flatten().long())\n",
    "        self.target.append(target.flatten().long())\n",
    "\n",
    "    def compute(self) -> Union[Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
    "                               Tuple[List[torch.Tensor], List[torch.Tensor], List[torch.Tensor]]]:\n",
    "\n",
    "        preds = torch.cat(self.preds, dim=0).cpu().numpy()\n",
    "        target = torch.cat(self.target, dim=0).cpu().numpy()\n",
    "        return matthews_corrcoef(preds, target), preds, target\n",
    "\n",
    "\n",
    "class ModelBigBird(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name: str, bertconfig: BertConfig, drop_mult: float, use_special_classifier:str):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bert = transformers.AutoModel.from_pretrained(model_name, add_pooling_layer=False)\n",
    "        self.bert.config = bertconfig\n",
    "        self.dropout_mult = drop_mult\n",
    "        self.dropout = nn.Dropout(self.dropout_mult)\n",
    "\n",
    "        sizes_classifier = [self.bert.config.hidden_size*4, self.bert.config.hidden_size, int(self.bert.config.hidden_size//2), 1]\n",
    "\n",
    "        if use_special_classifier == 'ln': \n",
    "            self.classifier = nn.Sequential(\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[0], sizes_classifier[1]),\n",
    "                nn.LayerNorm(sizes_classifier[1]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[1], sizes_classifier[2]),\n",
    "                nn.LayerNorm(sizes_classifier[2]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[2], sizes_classifier[3]),\n",
    "                nn.LayerNorm(sizes_classifier[3]),\n",
    "            )\n",
    "\n",
    "        elif use_special_classifier == 'bn': \n",
    "            self.classifier = nn.Sequential(\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[0], sizes_classifier[1]),\n",
    "                nn.BatchNorm1d(sizes_classifier[1]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[1], sizes_classifier[2]),\n",
    "                nn.BatchNorm1d(sizes_classifier[2]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[2], sizes_classifier[3]),\n",
    "                nn.BatchNorm1d(sizes_classifier[3]),\n",
    "            )\n",
    "\n",
    "        elif use_special_classifier == 'none': \n",
    "            self.classifier = nn.Sequential(\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[0], sizes_classifier[1]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[1], sizes_classifier[2]),\n",
    "                Mish(),\n",
    "                self.dropout,\n",
    "                nn.Linear(sizes_classifier[2], sizes_classifier[3])\n",
    "            )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_masks: torch.Tensor, device='cuda'):\n",
    "        out_bert = self.bert(input_ids, attention_masks, output_hidden_states=True)\n",
    "        hidden_states = out_bert[1]\n",
    "        h12 = hidden_states[-1][:,0]\n",
    "        h11 = hidden_states[-2][:,0]\n",
    "        h10 = hidden_states[-3][:,0]\n",
    "        h09 = hidden_states[-4][:,0]\n",
    "        concat_hidden = torch.cat([h09, h10, h11, h12], axis=-1)\n",
    "        out = self.classifier(concat_hidden)\n",
    "        return out\n",
    "\n",
    "    def freeze_bert_encoder(self):\n",
    "        print('Freezing all bert encoder')\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert_encoder(self):\n",
    "        print('Unreezing all bert encoder')\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze_bert_encoder_last_layers(self):\n",
    "        print('Unfreezing bert encoder last layers')\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            if \"encoder.layer.11\" in name or \"pooler\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def unfreeze_bert_encoder_pooler_layer(self):\n",
    "        print('Unfreezing bert encoder last pooler layer')\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            if \"pooler\" in name:\n",
    "                print(name)\n",
    "                param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "class EncodeCollateFn:\n",
    "\n",
    "    def slice_text(self, text):\n",
    "        split = text.split()\n",
    "        size = len(split)\n",
    "        if size > self.max_tokens:\n",
    "            new_text = split[:self.max_tokens//2] + split[-self.max_tokens//2:]\n",
    "            text = ' '.join(new_text)\n",
    "        return text\n",
    "\n",
    "    def __init__(self, tokenizer: AutoTokenizer, max_input_length=7680):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_tokens = max_input_length\n",
    "\n",
    "    def __call__(self, batch):\n",
    "\n",
    "        documents = [self.slice_text(x[0]) for x in batch]\n",
    "        labels = torch.tensor([x[1] for x in batch], dtype=torch.int8)\n",
    "\n",
    "        assert type(documents) == list, 'Needs to be a list of strings'\n",
    "        tokenized = self.tokenizer(documents, return_tensors='pt', padding=True, truncation=True, max_length=self.max_tokens)\n",
    "\n",
    "        return tokenized['input_ids'], tokenized['attention_mask'], labels\n",
    "\n",
    "\n",
    "# from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)\n",
    "\n",
    "\n",
    "class JEFDataset(Dataset):\n",
    "    def __init__(self, path, dep_var, text_col, lowercase):\n",
    "        super().__init__()\n",
    "        self.dep_var = dep_var\n",
    "        self.text_col = text_col\n",
    "        all_columns = [self.dep_var, self.text_col] + ['date_appeal_panel_ruling']\n",
    "\n",
    "        data = pd.read_parquet(path, columns=all_columns)    \n",
    "\n",
    "        if len(data) > 600_000:\n",
    "            print(f'Previous size of training data: {len(data)}. Selecting only last 5 years of the training dataset')\n",
    "            data.date_appeal_panel_ruling = pd.to_datetime(data.date_appeal_panel_ruling, infer_datetime_format=True, yearfirst=True, dayfirst=False)\n",
    "            thresh = data.date_appeal_panel_ruling.max() - timedelta(days=365*5)\n",
    "            data = data[data.date_appeal_panel_ruling >= thresh].copy()\n",
    "            print(f'New size of training data: {len(data)}')\n",
    "\n",
    "        data.drop('date_appeal_panel_ruling', axis=1, inplace=True)\n",
    "        data[self.dep_var] = data[self.dep_var].replace('PROVIMENTO PARCIAL', 'PROVIMENTO')\n",
    "        data = data[data[self.dep_var].isin(['PROVIMENTO', 'NÃO PROVIMENTO'])]\n",
    "        data[self.dep_var] = data[self.dep_var].map({'NÃO PROVIMENTO': 0, 'PROVIMENTO': 1})\n",
    "\n",
    "        if lowercase:\n",
    "            data[self.text_col] = data[self.text_col].str.lower()\n",
    "\n",
    "        print(f'Size before: {len(data)} - {path.split(\"/\")[-1]}')        \n",
    "        data.dropna(inplace=True)\n",
    "        print(f'Size after: {len(data)} - {path.split(\"/\")[-1]}')\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        self.data = data.copy()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, self.text_col], self.data.loc[idx, self.dep_var]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.num_labels = len(self.hparams['labels'])\n",
    "        self.tokenizer = BigBirdTokenizer.from_pretrained(self.hparams['bert_model_path'])\n",
    "        config = AutoConfig.from_pretrained(self.hparams['bert_model_path'])\n",
    "        config.__setattr__('num_labels', len(self.hparams['labels']))\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        self.mcc = MCC()\n",
    "        self.valor_mcc = {'val_mcc': -1, 'test_mcc': -1}\n",
    "        self.best_mcc = -1.0\n",
    "        self.precision_metric = torchmetrics.Precision(num_classes=self.num_labels)\n",
    "        self.recall_metric = torchmetrics.Recall(num_classes=self.num_labels)\n",
    "        #self.confmat = torchmetrics.ConfusionMatrix(num_classes=self.num_labels)\n",
    "        self.f1_score = torchmetrics.F1(num_classes=self.num_labels)\n",
    "\n",
    "        self.model = ModelBigBird(self.hparams['bert_model_path'],\n",
    "                                      bertconfig=config,\n",
    "                                      drop_mult=self.hparams.drop_mult,\n",
    "                                      use_special_classifier=self.hparams.use_special_classifier)\n",
    "\n",
    "        if self.hparams.bert_unfreeze_mode == 'encoder_last':\n",
    "            self.model.freeze_bert_encoder()\n",
    "            self.model.unfreeze_bert_encoder_last_layers()\n",
    "        elif self.hparams.bert_unfreeze_mode == 'pooler_last':\n",
    "            self.model.freeze_bert_encoder()\n",
    "            self.model.unfreeze_bert_encoder_pooler_layer()\n",
    "        elif self.hparams.bert_unfreeze_mode == 'all':\n",
    "            self.model.unfreeze_bert_encoder()\n",
    "        elif self.hparams.bert_unfreeze_mode == 'none':\n",
    "            self.model.freeze_bert_encoder()\n",
    "\n",
    "        if self.hparams.weighted_loss:\n",
    "            weights = torch.FloatTensor(self.hparams.train_weights)\n",
    "            print(f'Using weighted loss: {weights}')\n",
    "        else:\n",
    "            weights = None\n",
    "        # weight = torch.FloatTensor(self.hparams.train_weights).to(self.hparams.device) if self.hparams.train_weights is not None else None)\n",
    "        self.loss = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "        self.lr = self.hparams.lr\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def step(self, batch, step_name='train'):\n",
    "        thresh = self.hparams.thresh_step\n",
    "        input_ids, attention_masks, y = batch\n",
    "        logits = self.forward(input_ids, attention_masks).squeeze()\n",
    "        y = y.type_as(logits)\n",
    "        loss = self.loss(logits, y)\n",
    "\n",
    "        if step_name == 'train':\n",
    "            self.log('train_loss', loss, on_step=True, on_epoch=True,\n",
    "                     logger=True, prog_bar=True, sync_dist=True, sync_dist_op='mean')\n",
    "            result = {'train_loss': loss}\n",
    "            return loss\n",
    "\n",
    "        else:\n",
    "            self.log(f'{step_name}_loss', loss, on_step=False, on_epoch=True, logger=True,\n",
    "                     prog_bar=True, reduce_fx=torch.mean, sync_dist=True, sync_dist_op='mean')\n",
    "\n",
    "            y_pred = torch.sigmoid(logits)\n",
    "            y_pred = torch.where(y_pred > thresh, 1.0, 0.0).long()\n",
    "            y =  y.long()\n",
    "            #y_pred = torch.argmax(logits, dim=1)\n",
    "            self.accuracy(y_pred, y)\n",
    "            #self.mymetric(y_pred, y)\n",
    "            self.precision_metric(y_pred, y)\n",
    "            self.recall_metric(y_pred, y)\n",
    "            self.f1_score(y_pred, y)\n",
    "            #self.confmat(y_pred, y)\n",
    "            self.mcc(y_pred, y)\n",
    "\n",
    "    \n",
    "        result = {f'{step_name}_loss': loss}\n",
    "        return result\n",
    "        \n",
    "    def calculate_metrics(self, outputs, step_name='val'):\n",
    "        \n",
    "        mcc, preds, target = self.mcc.compute()\n",
    "        tn = ((target == preds) & (target == 0)).sum()\n",
    "        tp = ((target == preds) & (target == 1)).sum()\n",
    "        fn = ((target != preds) & (target == 1)).sum()\n",
    "        fp = ((target != preds) & (target == 0)).sum()\n",
    "\n",
    "        \n",
    "        outs = {}\n",
    "        outs[f'{step_name}_acc'] = self.accuracy.compute()\n",
    "        outs[f'{step_name}_loss'] = torch.mean(torch.tensor([i[f'{step_name}_loss'] for i in outputs]))\n",
    "        outs[f'{step_name}_tn'] = tn\n",
    "        outs[f'{step_name}_fp'] = fp\n",
    "        outs[f'{step_name}_fn'] = fn\n",
    "        outs[f'{step_name}_tp'] = tp\n",
    "        outs[f'{step_name}_f1_score'] = self.f1_score.compute()\n",
    "        outs[f'{step_name}_precision'] = self.precision_metric.compute()\n",
    "        outs[f'{step_name}_recall'] = self.recall_metric.compute()\n",
    "        outs[f'{step_name}_mcc'] = mcc\n",
    "        #outs[f'{step_name}_mccold'] = mcc2\n",
    "        #confmat = self.confmat.compute().long().detach().cpu().numpy()\n",
    "\n",
    "        self.recall_metric.reset()\n",
    "        self.precision_metric.reset()\n",
    "        self.f1_score.reset()\n",
    "        self.accuracy.reset()\n",
    "        self.mcc.reset()\n",
    "        #self.confmat.reset()\n",
    "\n",
    "        if float(mcc) > self.best_mcc:\n",
    "            self.best_mcc = float(mcc)\n",
    "            self.log('best_mcc', mcc)\n",
    "        if self.valor_mcc[f'{step_name}_mcc'] < float(outs[f'{step_name}_mcc']):\n",
    "            self.valor_mcc[f'{step_name}_mcc'] = float(outs[f'{step_name}_mcc'])\n",
    "\n",
    "        print(matthews_corrcoef(preds, target), mcc, len(target), len(preds))\n",
    "        if self.global_rank == 0:\n",
    "            print(matthews_corrcoef(preds, target), mcc, len(target), len(preds))\n",
    "            if self.valor_mcc[f'{step_name}_mcc'] < float(outs[f'{step_name}_mcc']):\n",
    "                self.valor_mcc[f'{step_name}_mcc'] = float(outs[f'{step_name}_mcc'])\n",
    "                #self.logger.experiment.log({f\"best_mcc-confusion_matrix\" : wandb.plot.confusion_matrix(preds=preds, y_true=target, class_names=[i[:3].upper() for i in self.hparams.labels])}, commit=False)\n",
    "            #print(\"\\n\\nCONFUSION MATRIX:\\n\", confmat, \"\\n\")\n",
    "            print(f\"{step_name}_acc: {float(outs[f'{step_name}_acc']):.5f}\")\n",
    "            print(f\"{step_name}_mcc: {float(outs[f'{step_name}_mcc']):.5f}\")\n",
    "            print(f\"Number of cases: {int(tn+fp+fn+tp)}\")\n",
    "            print('\\n')\n",
    "\n",
    "\n",
    "        for k, v in outs.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "    def forward(self, input_ids, attention_masks, *args):\n",
    "        return self.model(input_ids, attention_masks, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def validation_epoch_end(self, outputs: List[dict]):\n",
    "        return self.calculate_metrics(outputs, step_name='val')\n",
    "\n",
    "    def test_epoch_end(self, outputs: List[dict]):\n",
    "        return self.calculate_metrics(outputs, step_name='test')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "\n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        #print(self.hparams.cat_names)\n",
    "        return DataLoader(\n",
    "            JEFDataset(ds_path, self.hparams.dep_var, self.hparams.text_col, self.hparams.lowercase), \n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "            num_workers=int(cpu_count()),\n",
    "            collate_fn=EncodeCollateFn(self.tokenizer)\n",
    "        )\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == 'fit':\n",
    "            total_devices = max(1, self.hparams.n_gpus) * 1\n",
    "            train_batches = len(self.train_dataloader()) // total_devices\n",
    "            self.train_steps = math.ceil((self.hparams.epochs * train_batches) / self.hparams.accumulate_grad_batches)\n",
    "            self.train_steps = int(math.ceil(self.train_steps * 1.01))#1.04)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_steps = self.train_steps\n",
    "        optimizer = torch.optim.AdamW([p for p in self.model.parameters() if p.requires_grad], lr=self.lr, weight_decay=0.1)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                           max_lr=self.lr,\n",
    "                                                           total_steps=train_steps,\n",
    "                                                           three_phase=True,\n",
    "                                                           epochs=self.hparams.epochs)\n",
    "\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50413b2f-7ba9-4440-823d-8e735a7496ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/envs/paper_brcad5/lib/python3.9/site-packages/deprecate/deprecation.py:115: FutureWarning: The `F1` was deprecated since v0.7 in favor of `torchmetrics.classification.f_beta.F1Score`. It will be removed in v0.8.\n",
      "  stream(template_mgs % msg_args)\n",
      "Some weights of the model checkpoint at ./bigbird-jus were not used when initializing BigBirdModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'bert.pooler.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing all bert encoder\n",
      "Unfreezing bert encoder last layers\n",
      "Using weighted loss: 3.8351831436157227\n"
     ]
    }
   ],
   "source": [
    "learn = TrainingModule.load_from_checkpoint('./bigbird-best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573aed60-19e2-4e45-9d08-77e7390d5c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()\n",
    "learn.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92997357-4c7c-49c1-95d2-de8b8bcb2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to('cuda:1'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0fd6e64-54ee-499e-a0a6-e5ea47f32300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e716ab3-8785-418e-afb8-a520a9f5bc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"accumulate_grad_batches\": 2\n",
       "\"batch_size\":              8\n",
       "\"bert_model_path\":         ./bigbird-jus\n",
       "\"bert_unfreeze_mode\":      encoder_last\n",
       "\"dep_var\":                 label\n",
       "\"deterministic\":           True\n",
       "\"device\":                  cuda\n",
       "\"drop_mult\":               0.3\n",
       "\"epochs\":                  15\n",
       "\"gradient_clip_val\":       10.0\n",
       "\"hparams\":                 Namespace(train_path='../data/train_en.parquet', val_path='../data/valid_en.parquet', test_path='../data/test_en.parquet', batch_size=8, epochs=15, drop_mult=0.3, use_special_classifier='none', lowercase=False, lr=0.0003, thresh_step=0.49, accumulate_grad_batches=2, gradient_clip_val=10.0, stochastic_weight_avg=True, dep_var='label', text_col='preprocessed_full_text_first_instance_court_ruling', bert_model_path='./bigbird-jus', labels=[0, 1], sync_batchnorm=True, device='cuda', train_weights=array(3.835183, dtype=float32), bert_unfreeze_mode='encoder_last', weighted_loss=True, precision='bf16', n_gpus=2, deterministic=True)\n",
       "\"labels\":                  [0, 1]\n",
       "\"lowercase\":               False\n",
       "\"lr\":                      0.0003\n",
       "\"n_gpus\":                  2\n",
       "\"precision\":               bf16\n",
       "\"stochastic_weight_avg\":   True\n",
       "\"sync_batchnorm\":          True\n",
       "\"test_path\":               ../data/test_en.parquet\n",
       "\"text_col\":                preprocessed_full_text_first_instance_court_ruling\n",
       "\"thresh_step\":             0.49\n",
       "\"train_path\":              ../data/train_en.parquet\n",
       "\"train_weights\":           3.8351831436157227\n",
       "\"use_special_classifier\":  none\n",
       "\"val_path\":                ../data/valid_en.parquet\n",
       "\"weighted_loss\":           True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd5187a-0758-4afd-8b2d-7cc281b47314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bigbird(model, text):\n",
    "    input_ids, attention_mask, _ = EncodeCollateFn(learn.tokenizer)([[text, 0]])\n",
    "    if model.device != 'cpu':\n",
    "        input_ids = input_ids.to(model.device) \n",
    "        attention_mask = attention_mask.to(model.device)\n",
    "    logits = model.forward(input_ids, attention_mask)\n",
    "    prob  = torch.sigmoid(logits)\n",
    "    y_pred = torch.where(prob > model.hparams.thresh_step, 1.0, 0.0).long()\n",
    "    return logits.cpu().numpy(), prob.cpu().numpy(), int(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e33be4bc-38bc-4a55-8560-18f1a1417bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='690' class='' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [690/690 00:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/envs/paper_brcad5/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:976: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)\n",
      "Attention type 'block_sparse' is not possible if sequence_length: 672 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3.Changing attention type to 'original_full'...\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'BigBird'\n",
    "DS_TYPE = 'humans'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "\n",
    "output_preds = []\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "\n",
    "for ruling in bar:\n",
    "    output_preds.append(predict_bigbird(learn, ruling))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4374ff51-b103-470f-9c03-333d4dbbd741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>humans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_pred          y_true    model ds_type\n",
       "0    NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird  humans\n",
       "1    NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird  humans\n",
       "2    NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird  humans\n",
       "3    NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird  humans\n",
       "4    NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird  humans\n",
       "..              ...             ...      ...     ...\n",
       "685      PROVIMENTO      PROVIMENTO  BigBird  humans\n",
       "686      PROVIMENTO  NÃO PROVIMENTO  BigBird  humans\n",
       "687  NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird  humans\n",
       "688      PROVIMENTO      PROVIMENTO  BigBird  humans\n",
       "689      PROVIMENTO      PROVIMENTO  BigBird  humans\n",
       "\n",
       "[690 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.Series([i[2] for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].replace({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0962591-5bf7-4a2f-b719-afb2b8e83852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "637cd9dc-3666-4b44-8d2e-b3e11199aa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='76299' class='' max='76299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [76299/76299 1:32:07<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'BigBird'\n",
    "DS_TYPE = 'test'\n",
    "DS = df_humans if DS_TYPE == 'humans' else df_test\n",
    "\n",
    "output_preds = []\n",
    "bar = progress_bar(DS.preprocessed_full_text_first_instance_court_ruling.values)\n",
    "\n",
    "for ruling in bar:\n",
    "    output_preds.append(predict_bigbird(learn, ruling))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b6807b-5d71-4496-b798-9664151a5051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76294</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76295</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76296</th>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>NÃO PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76297</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76298</th>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>PROVIMENTO</td>\n",
       "      <td>BigBird</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               y_pred          y_true    model ds_type\n",
       "0      NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird    test\n",
       "1      NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird    test\n",
       "2      NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird    test\n",
       "3      NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird    test\n",
       "4      NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird    test\n",
       "...               ...             ...      ...     ...\n",
       "76294      PROVIMENTO      PROVIMENTO  BigBird    test\n",
       "76295      PROVIMENTO      PROVIMENTO  BigBird    test\n",
       "76296  NÃO PROVIMENTO  NÃO PROVIMENTO  BigBird    test\n",
       "76297      PROVIMENTO      PROVIMENTO  BigBird    test\n",
       "76298      PROVIMENTO      PROVIMENTO  BigBird    test\n",
       "\n",
       "[76299 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.Series([i[2] for i in output_preds], name='y_pred').to_frame()\n",
    "df_preds['y_true'] = DS.label.values\n",
    "df_preds['y_pred'] = df_preds['y_pred'].replace({0:'NÃO PROVIMENTO', 1:'PROVIMENTO'})\n",
    "df_preds['model'] = MODEL_NAME\n",
    "df_preds['ds_type'] = DS_TYPE\n",
    "df_preds.to_csv(f'predictions/{MODEL_NAME}-{DS_TYPE}.csv', index=False)\n",
    "joblib.dump(output_preds, f'predictions/raw-{MODEL_NAME}-{DS_TYPE}.joblib')\n",
    "df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb10d46-7d84-4c3c-bc15-5f6513267b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751de99-7289-4e4a-8fd8-ffebd22e5cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_paper_brcad5",
   "language": "python",
   "name": "conda_paper_brcad5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
